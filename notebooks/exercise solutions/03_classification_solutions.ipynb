{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b4c9857",
   "metadata": {},
   "source": [
    "# Classification: answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c43446",
   "metadata": {},
   "source": [
    "## Step 0: Getting setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a1907e",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a3c117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch framework\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Basic libraries\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from typing import Tuple, Dict, List\n",
    "import numpy as np\n",
    "import random\n",
    "import pathlib\n",
    "import os\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80641efc",
   "metadata": {},
   "source": [
    "### Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4758f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2050bf56",
   "metadata": {},
   "source": [
    "## Exercise 1: Prepare the train_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b5a8c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup train path\n",
    "image_path = Path(\"../datasets/Transport_Dataset\")\n",
    "train_dir = image_path / \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b56976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data transform \n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.RandomHorizontalFlip(p = 0.5),\n",
    "    transforms.RandomAutocontrast(p = 0.2),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean = [0.485, 0.456, 0.406], \n",
    "                         std = [0.229, 0.224, 0.225]) \n",
    " \n",
    "])\n",
    "\n",
    "# Use ImageFolder to create the train_dataset\n",
    "train_data = datasets.ImageFolder(\n",
    "    root = train_dir,  # Target folder of images\n",
    "    transform = train_transform  # Transforms to perform on train data (images)\n",
    ")\n",
    "\n",
    "# Create the train_dataloader\n",
    "train_dataloader = DataLoader(dataset = train_data, \n",
    "                              batch_size = 8, # Samples per batch\n",
    "                              shuffle = True) # Shuffle training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5fb0e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names (list): ['airplanes', 'cars', 'ship']\n",
      "Class names (dictionary): {'airplanes': 0, 'cars': 1, 'ship': 2}\n",
      "Length of train_data: 3000\n"
     ]
    }
   ],
   "source": [
    "# Get class names as a list\n",
    "class_names = train_data.classes\n",
    "print(\"Class names (list):\", class_names)\n",
    "\n",
    "# Get class names as a dictionary\n",
    "class_dict = train_data.class_to_idx\n",
    "print(\"Class names (dictionary):\", class_dict)\n",
    "\n",
    "# Check the lengths\n",
    "print(\"Length of train_data:\", len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a729b324",
   "metadata": {},
   "source": [
    "## Exercise 2: Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec9a9c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, output_shape:int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3*224*224, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_shape),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dadb26e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationModel(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=150528, out_features=512, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ClassificationModel(output_shape = 3)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4c02c4",
   "metadata": {},
   "source": [
    "# Exercise 3: Build the train loop, select a loss function and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163f80b2",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6a7d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, num_epochs = 20):\n",
    "    size = len(train_dataloader.dataset)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for batch, (inputs, labels) in enumerate(train_dataloader):\n",
    "            \n",
    "            # Send data to GPU if available\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 2. Calculate loss (per batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 3. Backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Optimizer step\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 5. Optimizer zero grad\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Print the loss per batch \n",
    "            if batch % 100 == 0:\n",
    "                loss, current = loss.item(), (batch + 1) * len(inputs)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e169db18",
   "metadata": {},
   "source": [
    "### Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdeb477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e24e7f",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "196ac5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "loss: 1.147939  [    8/ 3000]\n",
      "loss: 1.067240  [  808/ 3000]\n",
      "loss: 0.685624  [ 1608/ 3000]\n",
      "loss: 0.738351  [ 2408/ 3000]\n",
      "Epoch 1/4\n",
      "----------\n",
      "loss: 0.319932  [    8/ 3000]\n",
      "loss: 0.592264  [  808/ 3000]\n",
      "loss: 0.457773  [ 1608/ 3000]\n",
      "loss: 0.431327  [ 2408/ 3000]\n",
      "Epoch 2/4\n",
      "----------\n",
      "loss: 0.532519  [    8/ 3000]\n",
      "loss: 0.351893  [  808/ 3000]\n",
      "loss: 0.287844  [ 1608/ 3000]\n",
      "loss: 0.875251  [ 2408/ 3000]\n",
      "Epoch 3/4\n",
      "----------\n",
      "loss: 0.365434  [    8/ 3000]\n",
      "loss: 0.067380  [  808/ 3000]\n",
      "loss: 0.132662  [ 1608/ 3000]\n",
      "loss: 0.434515  [ 2408/ 3000]\n",
      "Epoch 4/4\n",
      "----------\n",
      "loss: 0.285315  [    8/ 3000]\n",
      "loss: 0.295276  [  808/ 3000]\n",
      "loss: 0.398224  [ 1608/ 3000]\n",
      "loss: 0.346211  [ 2408/ 3000]\n"
     ]
    }
   ],
   "source": [
    "train(model, loss, optimizer, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d2c2c",
   "metadata": {},
   "source": [
    "# Exercise 4: Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "877a0705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "MODEL_PATH = \"../data/models/baseline_model_TransportDataset.pth\"\n",
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0115c69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model (now you can use it for inference or evaluation)\n",
    "model = ClassificationModel(3).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location = DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d21cdb5",
   "metadata": {},
   "source": [
    "> Currently, we have completed the model training, but its ability to generalize the learned knowledge remains unkown. To assess its performance, in notebook **\"04_evaluation_methods_results\"**, we will examine examples of inference on the test dataset and obtain metrics that determine how well the model performs on unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b558538d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
